{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertisers = [\n",
    "\"614186325698777\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_next_page(response):\n",
    "    paging = response.get(\"paging\", {})\n",
    "    next_url = paging.get(\"next\", None)\n",
    "    return next_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(api_url):\n",
    "    all_data = []\n",
    "\n",
    "    while api_url:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            json_data = response.json()\n",
    "            data = json_data.get(\"data\", [])\n",
    "            all_data.extend(data)\n",
    "            api_url = get_next_page(json_data)\n",
    "        else:\n",
    "            print(\"Error:\", response.status_code)\n",
    "            break\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Extracted Data written to custom_ads\\data_614186325698777.json\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"custom_ads\"  # Directory to save the JSON files\n",
    "\n",
    "\n",
    "for id in advertisers:\n",
    "    fields = \"id,ad_snapshot_url,ad_creation_time,ad_creative_bodies,ad_creative_link_captions,ad_creative_link_descriptions,ad_creative_link_titles,ad_delivery_start_time,ad_delivery_stop_time,bylines,currency,delivery_by_region,demographic_distribution,estimated_audience_size,impressions,languages,page_id,page_name,publisher_platforms,spend,target_locations,target_gender,target_ages,eu_total_reach,beneficiary_payers,age_country_gender_reach_breakdown\"\n",
    "    # supported_countries = ['CZ']\n",
    "    limit = '100'\n",
    "    start_date = '2024-01-01'\n",
    "    ad_type = 'ALL'\n",
    "    access_token = \"EAALnc8im5MUBO0fdvFfWGLBzrHRXmnlg4GJbSZAxiHmDHd5cZAupnfxcOCZC2Jmm1HYWTjd8Rk1kQuOoZC86uur7n8zhrtIfntx0xjVOZACfXArwnu700VOZBOFze4Xsuw5ui6LqbSXPTyNs9UPZB0nbfcu1PgJjb147aMMTUjv5jZB0O3JMJ56AZCG3bD8nnwqjiiEQOsVeT\"\n",
    "    api_url = f\"https://graph.facebook.com/v17.0/ads_archive?search_terms=&ad_type={ad_type}&ad_delivery_date_min={start_date}&ad_reached_countries=['CZ']&access_token={access_token}&unmask_removed_content=true&search_page_ids={id}&fields={fields}&limit={limit}]\"\n",
    "    extracted_data = main(api_url)\n",
    "\n",
    "    # Write the extracted data to a JSON file\n",
    "    filename = os.path.join(output_dir, f\"data_{id}.json\")\n",
    "    with open(filename, \"w\", encoding='utf-8') as json_file:\n",
    "                json.dump(extracted_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"All Extracted Data written to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def replace_id_with_underscore_id(json_data):\n",
    "    if isinstance(json_data, dict):\n",
    "        for key, value in list(json_data.items()):\n",
    "            if key == \"id\":\n",
    "                json_data[\"_id\"] = json_data.pop(\"id\")\n",
    "            replace_id_with_underscore_id(value)\n",
    "    elif isinstance(json_data, list):\n",
    "        for item in json_data:\n",
    "            replace_id_with_underscore_id(item)\n",
    "\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    replace_id_with_underscore_id(data)\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "def replace_id_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            process_json_file(file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    replace_id_in_folder(output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### push data to mongo\n",
    "\n",
    "update if exists\n",
    "\n",
    "insert if not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data_614186325698777.json, Total documents processed: 61\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connection to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "# Select your database\n",
    "db = client['meta_ads_db']\n",
    "\n",
    "# Select your collection\n",
    "collection = db['meta_ads_collection']\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Load data from JSON file with 'utf-8' encoding\n",
    "        with open(file_path, encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Upsert each document from the JSON file\n",
    "        for document in data:\n",
    "            result = collection.update_one(\n",
    "                {\"_id\": document[\"_id\"]},\n",
    "                {\"$set\": document},\n",
    "                upsert=True\n",
    "            )\n",
    "        # Print the total number of documents added or updated for the current file\n",
    "        print(f\"File: {filename}, Total documents processed: {len(data)}\")\n",
    "\n",
    "\n",
    "# Close the connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop entire db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connection to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "# Select your database\n",
    "db = client['meta_ads_db']\n",
    "\n",
    "# Select your collection\n",
    "collection = db['meta_ads_collection']\n",
    "\n",
    "# Truncate (remove all documents from) the collection\n",
    "result = collection.delete_many({})\n",
    "\n",
    "# Print the number of deleted documents\n",
    "print(f\"Number of documents deleted: {result.deleted_count}\")\n",
    "\n",
    "# Close the connection\n",
    "client.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
